# Kuhn Poker 示例详解

本章以"总-分-总"结构说明 Kuhn Poker 最小实现的意义、使用方式与训练结果分析。

## 本节目的（总）

- 提供最小可运行的验证环境，理解 CFR 训练流程
- 通过简单博弈验证算法正确性，为扩展到复杂博弈打基础
- 展示如何从代码层面理解 GTO 策略的生成过程

## Kuhn Poker 规则（分）

### 游戏规则

- **牌数**：3 张牌（J、Q、K），J < Q < K
- **玩家**：2 人
- **底注**：每人投入 1 筹码
- **流程**：
  1. 每人发 1 张牌（不看对方牌）
  2. 玩家 1 先行动：过牌（check）或下注 1 筹码（bet）
  3. 如果玩家 1 过牌，玩家 2 必须过牌，直接比牌
  4. 如果玩家 1 下注，玩家 2 选择：跟注（call）或弃牌（fold）
  5. 如果跟注，比牌；如果弃牌，玩家 1 获胜

### 为什么选择 Kuhn Poker

- **状态空间小**：只有 3 张牌、2 个玩家、有限行动，便于验证算法
- **有已知解**：存在理论最优策略，可以验证结果正确性
- **包含核心要素**：信息不完美、行动选择、均衡策略，具备完整博弈特征

## 代码结构（分）

### 游戏定义：`solver/game/kuhn.py`

```python
class KuhnPoker:
    """Kuhn Poker 游戏定义"""
    
    def get_initial_state(self):
        """返回初始状态（发牌、底注）"""
        
    def get_legal_actions(self, state):
        """返回当前状态的合法行动"""
        
    def apply_action(self, state, action):
        """应用行动，返回新状态"""
        
    def is_terminal(self, state):
        """判断是否为终局"""
        
    def get_payoff(self, state):
        """计算终局收益"""
```

### CFR 算法：`solver/core/cfr.py`

```python
class CFR:
    """Counterfactual Regret Minimization 算法"""
    
    def train(self, iterations):
        """训练指定轮次"""
        
    def get_strategy(self, info_set):
        """获取信息集合的策略"""
        
    def update_regret(self, info_set, action, regret):
        """更新后悔值"""
```

### 训练入口：`solver/training/train_kuhn.py`

- 初始化游戏与 CFR 算法
- 执行训练循环
- 记录策略与收敛指标

### CLI 工具：`solver/cli/run_kuhn.py`

- 命令行参数解析
- 训练执行与结果输出
- 策略可视化（可选）

## 运行方式（分）

### 基本运行

```bash
# 训练 50000 轮
python -m solver.cli.run_kuhn --iterations 50000

# 指定输出文件
python -m solver.cli.run_kuhn --iterations 50000 --output data/kuhn_strategy.json

# 显示详细日志
python -m solver.cli.run_kuhn --iterations 50000 --verbose
```

### 参数说明

- `--iterations`：训练轮次（建议 50000+ 以获得稳定策略）
- `--output`：策略输出文件路径
- `--verbose`：显示详细训练过程

## 训练结果分析（分）

### 理论最优策略

Kuhn Poker 的理论最优策略为：

- **玩家 1（先手）**：
  - 拿到 K：100% 下注
  - 拿到 Q：1/3 下注，2/3 过牌
  - 拿到 J：100% 过牌

- **玩家 2（后手）**：
  - 如果玩家 1 过牌：
    - 拿到 K：100% 过牌（比牌）
    - 拿到 Q：100% 过牌
    - 拿到 J：100% 过牌
  - 如果玩家 1 下注：
    - 拿到 K：100% 跟注
    - 拿到 Q：1/3 跟注，2/3 弃牌
    - 拿到 J：100% 弃牌

### 验证指标

训练后应检查：

1. **策略收敛性**：策略是否稳定（最后 1000 轮变化 < 1%）
2. **与理论解对比**：计算策略与理论最优策略的差异（应 < 5%）
3. **期望收益**：两个玩家的期望收益应接近 0（零和博弈）

### 结果解读

- **策略频率**：查看各信息集合的下注/跟注频率
- **后悔值**：观察后悔值收敛趋势（应逐步减小）
- **收敛速度**：记录达到稳定策略所需的轮次

## 扩展方向（分）

### 短期扩展

1. **Leduc Poker**：扩展到 2 轮下注的简化德州
2. **策略可视化**：绘制策略树与频率热力图
3. **性能优化**：向量化计算、并行训练

### 长期扩展

1. **德州抽象**：3 张牌抽象、单街简化
2. **多街建模**：翻牌、转牌、河牌完整流程
3. **大规模训练**：支持百万级轮次的高效训练

## 常见问题（分）

### Q: 训练不收敛怎么办？

- 检查迭代次数是否足够（建议 50000+）
- 验证游戏定义是否正确
- 检查 CFR 算法实现是否有 bug

### Q: 策略与理论解差异较大？

- 增加训练轮次
- 检查随机种子是否影响结果
- 验证信息集合的编码是否正确

### Q: 如何理解生成的策略？

- 查看各信息集合的策略分布
- 对比理论最优策略
- 分析不同手牌下的行动频率

## 总结（总）

Kuhn Poker 示例是理解 CFR 算法与 GTO 策略生成的理想起点。通过运行代码、分析结果、对比理论解，可以深入理解：

- **博弈树遍历**：如何遍历所有可能的状态与行动
- **信息集合**：如何处理信息不完美的情况
- **策略更新**：如何通过后悔值最小化逐步逼近均衡
- **收敛验证**：如何判断策略是否达到最优

掌握 Kuhn Poker 后，可以逐步扩展到更复杂的博弈，最终实现德州扑克的 GTO Solver。
